# importing important packages
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
import math
#from sklearn import metrics
#from sklearn.svm import SVR, LinearSVR
# reading the dataSet
train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")

#transfer the data format from string to int
#from sklearn import preprocessing
    
#train_data['penalty']=train_data['penalty'].replace(['none'],['l2'])
#test_data['penalty']=test_data['penalty'].replace(['none'],['l2'])
def pen(a,b):
    if a == 'elasticnet':
        return b
    else:
        return 0
    
train_data['l1_ratio']= train_data.apply(lambda x: pen(x.penalty,x.l1_ratio),axis=1)
test_data['l1_ratio']= test_data.apply(lambda x: pen(x.penalty,x.l1_ratio),axis=1)

train_data=pd.get_dummies(train_data)
test_data=pd.get_dummies(test_data)

#train_hot=pd.get_dummies(train_data['alpha'])
#train_data=pd.concat([train_data,train_hot],axis=1)
#test_hot=pd.get_dummies(test_data['alpha'])
#test_data=pd.concat([test_data,test_hot],axis=1)

def mul_col(a,b,c):
    return a*b*c

train_data['n_jobs']=train_data['n_jobs'].replace([-1],[16])
test_data['n_jobs']=test_data['n_jobs'].replace([-1],[16])

train_data['max_iter']=mul_col(train_data['max_iter'],train_data['n_samples'],train_data['n_features'])
test_data['max_iter']=mul_col(test_data['max_iter'],test_data['n_samples'],test_data['n_features'])
#train_data['max_iter']=train_data['max_iter']/train_data['n_jobs']
#test_data['max_iter']=test_data['max_iter']/test_data['n_jobs']

train_data.drop(['id','n_samples','n_features','random_state','alpha','n_informative','scale'],axis=1,inplace=True)
test_data.drop(['id','n_samples','n_features','random_state','alpha','n_informative','scale'],axis=1,inplace=True)

train_data['time']= train_data['time'].apply(lambda x: math.log(x))

x_train=train_data#[train_data['time']<40]
    
 #split dataSet into train and test
#from sklearn.model_selection import train_test_split
#train, test = train_test_split(train_data, test_size=0.2, random_state=1)
y_train = x_train['time']
x_train = x_train.drop('time', axis=1)  

#x_test=test.drop('time',axis=1)
#y_test=test['time']
x_train=x_train.values
y_train=y_train.values
test_data=test_data.values

mean = x_train.mean(axis=0)
std = x_train.std(axis=0)
x_train = (x_train - mean) / std
test_data = (test_data - mean) / std

def build_model():
  model = keras.Sequential([
    keras.layers.Dense(120, activation=tf.nn.relu,
                       input_shape=(x_train.shape[1],)),
    keras.layers.Dense(60, activation=tf.nn.relu),
    keras.layers.Dense(30, activation=tf.nn.relu),
    keras.layers.Dense(1)
  ])

  optimizer = tf.train.RMSPropOptimizer(0.0003)

  model.compile(loss='mse',
                optimizer=optimizer,
                metrics=['mae'])
  return model



# Display training progress by printing a single dot for each completed epoch
class PrintDot(keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs):
    if epoch % 100 == 0: print('')
    print('.', end='')

EPOCHS = 500

import matplotlib.pyplot as plt

def plot_history(history):
  plt.figure()
  plt.xlabel('Epoch')
  plt.ylabel('Mean Abs Error [1000$]')
  plt.plot(history.epoch, np.array(history.history['mean_absolute_error']),
           label='Train Loss')
  plt.plot(history.epoch, np.array(history.history['val_mean_absolute_error']),
           label = 'Val loss')
  plt.legend()
  plt.ylim([0, 5])
  
model = build_model()
model.summary()
# The patience parameter is the amount of epochs to check for improvement
early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=20)

history = model.fit(x_train, y_train, epochs=EPOCHS,
                    validation_split=0.2, verbose=0,
                    callbacks=[early_stop, PrintDot()])

plot_history(history)

#[loss, mae] = model.evaluate(test_data, test_labels, verbose=0)

#print("Testing set Mean Abs Error: ${:7.2f}".format(mae * 1000))

test_predictions = model.predict(test_data).flatten()
for i in range(100):
    test_predictions[i]=math.exp(test_predictions[i])
#y_pred = reg.predict(x_test)

#y_pred = (y_pred_xg + y_pred_rf) / 2
#loss = metrics.mean_squared_error(y_test, y_pred)
#print(loss)
